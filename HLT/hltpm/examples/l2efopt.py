# Copyright (C) 2002-2017 CERN for the benefit of the ATLAS collaboration

# -- CUT FROM THIS POINT UPWARDS --
# This dump was automatically generated by myopt
# User rabello (Andre DOS ANJOS (PH)) at Tue Oct 16 14:29:49 2007

# All options should be inside the 'option' dictionary
# The keys being the long name of the options and the
# values, the new default to be attributed.
option = {}

# ================================
# 'Dataflow' options 
# ================================

# If we should use the real ROS instead of the ROSE
option['use-ros'] = False

# Maximum number of events to run the L2SV for (0 means forever
option['max-events'] = 0

# List of data files to preload or the size of the dummy ROBs (for partitions with ROSs/ROSEs) or the dummy event (for partitions with an SFI emulator)
option['data'] = ['/pcatr-srv2/data1/MixedEventsRel13/BS/daq.csc13.0000000.Single.Stream.LB0000.Athena._0001_ordered.data']

# List of directories where to place (SFI/O) output files. If you are using an SFO, the first entry in this list will be also used to place the index files.
option['write-dir'] = []

# ================================
# 'Farm size' options 
# ================================

# Number of PTs per EF machine. The magic number zero will switch the use of templates off for the PTs and EFDs.
option['pts-per-efd'] = 4

# Number of L2PU's per node. The magic number zero will switch the use of templates off for the L2PUs.
option['l2pus-per-node'] = 2

# Number of L2PU worker threads
option['l2pu-worker'] = 1

# ================================
# 'HLT' options 
# ================================

# Defines the L2 HLT Implementation to use. It has to be either a python dictionary (like the default argument), a dictionary that configures an HLTImplementation, or a string, that determines the path to the jobOptions to use. This parameter can also be set to dal.HLTImplementation object that will be used blindly to configure the L2 system at your partition.
option['l2-hlt'] = {'preCommand': ['isOnline=True'], 'jobOptionsPath': 'TriggerRelease/testHLT_standalone.py'}

# Defines the EF HLT Implementation to use. It has to be either a python dictionary (like the default argument), a dictionary that configures an HLTImplementation, or a string, that determines the path to the jobOptions to use. This parameter can also be set to dal.HLTImplementation object that will be used blindly to configure the EF system at your partition.
option['ef-hlt'] = {'jobOptionsPath': 'TriggerRelease/testHLT_standalone.py'}

# Defines a set of extra paths that should contain valid installation areas where you have patches for the HLT/Offline software. The order you set is preserved. These areas are attached both to L2 and EF HLT nodes.
option['hlt-extra-path'] = ['/afs/cern.ch/atlas/project/hlt/testing/13.0.30/patches']

# If you set this option, it should be the fully-qualified host name of the host that runs the top-level DB proxy for HLT applications. In this case, we will populate the generated segment or partition with DB proxies where they fit. If you do not set this option, the default action is not to place any DB proxies.
option['top-db-proxy'] = 'pc-tdq-onl-10.cern.ch:3307'

# ================================
# 'Machine allocation' options 
# ================================

# This parameter defines the name of a python module that contains a dictionary named "ebef_farm". This dictionary should contain the python farm description of the EB-EF farm as described at the documentation of the function "gen_ebef_segment" at the submodule pm.multinode. If the module contains another variable called "includes", it will be used as the OKS hardware database and will be included in the final generated database
option['ebef-farm'] = 'myfarm'

# This parameter defines the name of a python module that contains a dictionary named "ros_farm". This dictionary should contain the python farm description of the ROS farm as described at the documentation of the function "gen_ros_segment" at the submodule pm.multinode. If the module contains another variable called "includes", it will be used as the OKS hardware database and will be included in the final generated database
option['ros-farm'] = 'myfarm'

# This parameter defines the name of a python module that contains a dictionary named "l2_farm". This dictionary should contain the python farm description of the LVL2 farm as described at the documentation of the function "gen_l2_segment" at the submodule pm.multinode. If the module contains another variable called "includes", it will be used as the OKS hardware database and will be included in the final generated database
option['l2-farm'] = 'myfarm'

# If this option is set, we will localhost'ify your segment or partition object, so every reference to external computers is removed. The resulting product will run on the default host, which is normally defined as the localhost.
option['localhost'] = False

# ================================
# 'Partition making' options 
# ================================

# Add a RepositoryRoot to the partition
option['repository-root'] = ''

# If this flag is set, the output will not contain any applications, but just the control tree (useful for controller-only tests)
option['control-only'] = False

# The name of the OKS partition
#option['partition-name'] = 'part_l2efhlt_atr'

# If this option is set, we will remove all templates from your segment or partition object transforming them in plain non-templated applications, respecting the number of instances of each of those you actually want to run in every machine.
option['no-templates'] = False

# Which setup file to include in your partition
option['setup-file'] = 'daq/segments/setup.data.xml'

# Extra OKS includes to your output
option['extra-includes'] = []

# Post processing option
option['post-processor'] = ['postproc']
